# Ignored Files Summary

Files excluded from fingerprint analysis via `.dev-report-fingerprint-ignore`. These are runtime artifacts, logs, and volatile state files that would otherwise cause false cache misses on every pipeline run.

---

## `references/examples/token_economics.log` / `token_economics.log`

**What it is:** JSONL append-only log of token usage per pipeline phase, written by `scripts/token_logger.py`.

**Content summary:** Two categories of entries:

1. **Phase-level entries** — one per `append_usage()` call. Fields: `ts`, `phase`, `model`, `prompt_tokens`, `completion_tokens`, `total_tokens`, `cost`. Example:
   ```json
   {"ts":"2026-02-15T01:13:55Z","phase":"1.5","model":"haiku","prompt_tokens":0,"completion_tokens":0,"total_tokens":0,"cost":0.0}
   ```
   Tokens are all zero when running under `SUBSCRIPTION_MODE=true` (subscription auth; no API keys in play).

2. **Full-run entries** — one per complete pipeline invocation from `run_pipeline.py`. Fields: `ts`, `run`, `phase1_tokens`, `phase15_tokens`, `phase2_tokens`, `total_tokens`, `total_cost`. Example from 2026-02-16:
   ```json
   {"ts":"2026-02-16T21:14:33Z","phase":"full-run","model":"mixed","phase1_tokens":8233,"phase15_tokens":0,"phase2_tokens":2048,"total_tokens":10281,"total_cost":0.01273}
   ```

**Why ignored:** Appended after every run; changes timestamp and content on every invocation, immediately invalidating the fingerprint cache.

---

## `references/benchmarks.jsonl`

**What it is:** JSONL benchmark log appended by `run_pipeline.py` at the end of each full pipeline run.

**Content summary (12 recorded runs, all 2026-02-17):**

Each entry contains:
- `ts` — ISO timestamp
- `run` — label (all show `"cold"` due to a label-propagation bug during development)
- `cache_hit` — whether Phase 1 returned a cache hit
- `timings_sec` — per-phase wall times: `phase1`, `phase15`, `phase2`, `phase3`, `total`
- `phase15_tokens` / `phase2_tokens` — full token usage objects from Claude CLI JSON output
- `report` — output report path

**Performance summary across 12 runs:**

| Metric | Range |
|--------|-------|
| Phase 1 (data gather) | 0.69 – 1.03 s |
| Phase 1.5 (haiku draft) | 7.3 – 8.9 s |
| Phase 2 (sonnet polish) | 27.1 – 33.5 s |
| Phase 3 (cache verify) | ~0.001 s |
| Total pipeline | 35 – 43 s |

**Token patterns:**
- Phase 1.5: ~26k tokens first cold run (cache creation), drops to ~5–9k on subsequent runs (cache read). Output tokens: 167–289.
- Phase 2: ~23k tokens first cold run, ~5–6k on subsequent runs. Output tokens: 1,055–1,360.
- All `cost_usd: 0` — running under subscription auth, no API cost tracked.

**Why ignored:** A new entry is appended on every run; git-tracked status would dirty the fingerprint immediately.

---

## `build.log`

**What it is:** Human-readable running log of pipeline milestones and per-phase token summaries, written by `scripts/token_logger.py` (summary lines) and manually during development.

**Content summary:**

| Date/Time | Entry |
|-----------|-------|
| 2026-02-15T01 | Token usage log initialized |
| 2026-02-15T01:13 | Phase 1.5 stub run: 0 tokens (no API) |
| 2026-02-15T01:13 | Phase 1 replay + Phase 1.5 fallback; Phase 2 stub |
| 2026-02-15T02:04 | Codex run failed: backend stream disconnect |
| 2026-02-15T02:19 | Codex run retry failed: backend stream disconnect |
| 2026-02-15T02:31 | Codex test report succeeded; output `codex-test-report-20260215T022940Z.md`; phase3 fp None (legacy payload) |
| 2026-02-15T02:35 | Phase 1 updated to compact payload + background runner |
| 2026-02-15T02:52 | Codex test report succeeded (compact payload); output `codex-test-report-20260215T025110Z.md`; phase3 fp present |
| 2026-02-17T04:34–51 | ~12 pipeline test runs via `run_pipeline.py`; all 0 tokens (subscription mode) |

Entries from 2026-02-17 are phase-level token lines added automatically by `token_logger.py` on each `run_pipeline.py` invocation. All show `0 tokens, Cost: $0.0000` since API key is not configured (subscription mode).

**Why ignored:** Appended on every run; also `.log` extension pattern covers it.

---

## `~/.claude/usage-data/report.html` (INSIGHTS_REPORT_PATH)

**What it is:** Claude Code Insights — an analytics HTML report generated by the Claude Code platform covering session usage, tool patterns, wins/friction, and feature suggestions.

**Coverage:** 197 messages across 19 sessions, 2026-02-14 to 2026-02-16.

**Key stats:**
- Sessions: 19 over 3 days (avg ~6.6/day)
- Top tool: Bash (83 calls), Read (32), Edit (30), Write (8), Task (8), Glob (4)
- Languages touched: Markdown (52 files), Shell (29), Python (19), JSON (14), YAML/Config (10)
- Work split: ~60% original work, ~40% forked/modified

**5 work areas identified:**
1. PR Reviews & merges (5 sessions) — multi-repo review lifecycle
2. Skill development (4 sessions) — dev-activity-report skill, cache/fingerprint work
3. Statusline tooling (4 sessions) — ccusage integration, usage % calculation bugs
4. Git operations (4 sessions) — feature branch management, commit discipline
5. Build history updates (2 sessions) — documentation maintenance

**Wins documented:**
- Multi-repo PR review and merge lifecycle completed in single sessions
- Iterative skill development with build-and-verify discipline; cache fingerprinting bug caught during warm-cache verification
- Self-improving Claude configuration: feeding insights back into CLAUDE.md via PRs

**Friction documented:**
- Calculation/logic errors requiring multiple corrections (usage % formula took 2+ rounds)
- Misinterpreted request scope (credential rotation confused with CLAUDE.md content)
- Subtle cache/file operation bugs (mtime fingerprinting bug only caught during verification)
- Assumed JSON field names without validating source data first (3+ sessions)

**Feature suggestions generated by the report:**
- Hooks (`postEditFile`) for auto-linting `.py` and `.sh` files on save
- Headless mode for automated PR review pipelines
- CLAUDE.md additions: data validation pattern, prompt caching awareness

**Patterns suggested:**
- Formalize PR review into a repeatable skill + headless command
- Always inspect raw JSON output before writing parsers
- Replace status-check sessions with shell aliases

**On the horizon:**
- Autonomous PR review pipeline with parallel sub-agents (code quality + tests + security scanning in parallel)
- Self-healing statusline with test-driven iteration loop
- Skill development with automated cache validation (exactly what was built this session)

**Why ignored:** The insights file updates asynchronously (platform-side generation); its content hash changes between sessions, not between pipeline runs within a session. Including it in the fingerprint would cause false misses whenever a new report is generated. It is explicitly listed as the sole non-git fingerprint exception in `SKILL.md`.

---

## `~/.claude/todos/`, `~/.claude/tasks/`, `~/.claude/projects/`

**What they are:** Per-session task tracking files created and modified by Claude Code during interactive sessions. Each `claude -p` subprocess call creates new UUID-named subdirectories under `todos/`.

**Why ignored:** A new `todos/<uuid>/` directory is created for each `claude -p` invocation (Phase 1.5 and Phase 2 each create one). These would invalidate the `claude_home` fingerprint on every run, making warm cache hits impossible during active development.

---

## `~/.claude/debug/`, `*.txt`

**What they are:** Debug output files written by Claude Code for diagnostic purposes. Created automatically during sessions.

**Why ignored:** Created and updated during `claude -p` subprocess calls; change the `claude_home` fingerprint between pipeline phases.

---

## `~/.claude/settings.json`

**What it is:** Claude Code global settings — permissions (allow/deny lists), model selection, statusline config, plugin state.

**Current content summary:**
- `permissions.allow`: 45 entries including Bash patterns for git, gh, npm, python, and `Read(*)`
- `permissions.deny`: ls, find, grep, cat, head, tail, sed, awk, echo (enforcing tool-first policy from CLAUDE.md)
- `model`: `sonnet`
- `statusLine`: `bash /home/nate/.claude/statusline.sh`
- `alwaysThinkingEnabled`: false
- `promptSuggestionEnabled`: false

**Why ignored:** The allow list is modified during sessions when new tool permissions are approved; each approval mutates this file and would dirty the fingerprint.

---

## `~/.claude/stats-cache.json`, `plugins/install-counts-cache.json`, `plugins/installed_plugins.json`, `plugins/known_marketplaces.json`

**What they are:** Claude Code internal caches — session stats aggregation, plugin installation counts, installed plugin registry, known marketplace index.

**Why ignored:** Updated automatically by the Claude Code runtime on startup and during sessions. These are pure cache files with no user-authored content relevant to the activity report.

---

## `~/.claude/.credentials.json`

**What it is:** OAuth/API credentials and tokens for Claude Code authentication.

**Why ignored:** Security-sensitive; should never be included in any fingerprint or analysis. Content changes on token refresh.

---

## Summary Table

| File / Pattern | Category | Why Volatile |
|---|---|---|
| `token_economics.log` | Token metrics | Appended on every run |
| `build.log` | Build log | Appended on every run |
| `benchmarks.jsonl` | Benchmark data | Appended on every run |
| `report.html` | Insights analytics | Platform-generated; changes between sessions |
| `todos/*` | Session state | New UUID dir per `claude -p` call |
| `tasks/*`, `projects/*` | Session state | Per-session tracking |
| `debug/*`, `*.txt` | Debug output | Auto-created during sessions |
| `settings.json` | Config | Allow-list modified per session |
| `stats-cache.json` | Runtime cache | Updated on startup |
| `plugins/*.json` | Plugin cache | Updated by plugin manager |
| `.credentials.json` | Auth tokens | Refreshed automatically |

All patterns are listed in `skills/dev-activity-report-skill/.dev-report-fingerprint-ignore` and are applied in both `phase1_runner.py` (Python path) and the Claude CLI path (per SKILL.md Phase 1 documentation).
